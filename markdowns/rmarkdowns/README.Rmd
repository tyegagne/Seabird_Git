---
title: "FrontEndCompilation"
author: "Tyler Gagne"
date: "6/8/2017"
output: github_document
---

**A public repository for seabird CSIA-AA trophic position analysis**

This is a repository of abbreviated analysis script and markdown examples used to generate the figures in *Gagne, Hyrenbach, Hagemann, and Van Houtan, In Prep.*

**The file structure is as follows:**

**data** <- contains CSV and .rData files used in construction of markdowns
**markdowns** <- contains annotated markdowns for individual figure development 
**rMarkdowns** <- contains orginal RMarkdown scripts used to generate .md files

*A long markdown is below, see individual markdowns in *markdown* folder*

```{r "setup", include=FALSE}
knitr::opts_knit$set(root.dir = "/Users/tgagne/Seabird_Git/data/csv")
```


```{r, echo=FALSE,include=FALSE}
#Load libraries, datasets, working directories
library(dplyr)
library(plyr)
library(reshape)
library(grid)
library(ggplot2)
library(data.table)
library(mgcv)
library(gridExtra)
#setwd("/Users/tgagne/Seabird_Git/data/csv")
set.seed(4567)
#raw AA-isotope data
data<-read.csv('seabird_CSSIA_NPacific_1890_2016_rawdata.csv', header = T)
#Prey data for overlay
preyMTL_data<-read.csv('NEWpreyMTL_apr19.csv', header = T)
data <- droplevels( data[-which(data$spp == "RFBO"), ] )
#split speciment records up in to list by specimen id
dataList = split(data, data$uc_id)
```


**This is the function used to draw random compound amino acid estimate samples from the analytic lab's distributions**

A single AA isotope normal distribution from a single specimen was used to generate 1000 compound specific amino acid isotopic values. We then calculated 1000 trophic position estimates using the mean of six trophic AAs  and one source AA. 

*The constants for beta and TEF are included in the function*

```{r}

N <- 1000

GetTP <- function(anID){
  b = 2.4167
  TEF = 5.6333
  ala.est<- rnorm(N, mean = as.numeric(subset(anID, value == "ave", select = "ala")) , sd = as.numeric(subset(anID, value == "sd", select = "ala")))
  glu.est<- rnorm(N, mean = as.numeric(subset(anID, value == "ave", select = "glue")) , sd = as.numeric(subset(anID, value == "sd", select = "glue")))
  ile.est<- rnorm(N, mean = as.numeric(subset(anID, value == "ave", select = "ile")) , sd = as.numeric(subset(anID, value == "sd", select = "ile")))
  leu.est<- rnorm(N, mean = as.numeric(subset(anID, value == "ave", select = "leu")) , sd = as.numeric(subset(anID, value == "sd", select = "leu")))
  pro.est<- rnorm(N, mean = as.numeric(subset(anID, value == "ave", select = "pro")) , sd = as.numeric(subset(anID, value == "sd", select = "pro")))
  val.est<- rnorm(N, mean = as.numeric(subset(anID, value == "ave", select = "val")) , sd = as.numeric(subset(anID, value == "sd", select = "val")))
  phe.est<- rnorm(N, mean = as.numeric(subset(anID, value == "ave", select = "phe")) , sd = as.numeric(subset(anID, value == "sd", select = "phe")))
  TPforID <- (((((ala.est + glu.est + ile.est + leu.est + pro.est + val.est)/6)) - phe.est - b)/TEF ) + 1 
  return(TPforID)}
```


**We then run a *for* loop to generate longitudinal plots of trophic position across time.**

We generated the time series plot by randomly drawing one TP estimate from each available year and fitting a loess model through the data. The loess model was then used to predict TP through the entire sequence 1890 to 2015, which was appended in to a dataset. We repeated process 1000 times for each species and for the ensemble; the median, and the 2.5% and 97% quantiles were then plotted. 

```{r, echo=FALSE,include=FALSE}
TPforID_all = lapply(dataList, GetTP )                                  # apply function to list
TPforID_all = melt(TPforID_all)                                         # melt dataframe
TPforID_all$L1 <- as.factor(TPforID_all$L1)
setnames(TPforID_all, old=c("L1","value"), new=c("uc_id", "tp"))        # rename columns

#Remerge with orginal
data<-subset(data, value == "ave")
total<-merge(data,TPforID_all, by="uc_id")
```

```{r,fig.width=6, fig.height=13,fig.retina=2}
sppx<-c("LAAL","BUPE","WTSH","WTTR","BRBO","BRNO","WHTE","SOTE","TP")         # adjust order taxonomically 

S <- 1000

par(mfrow=c(5,2), mai = c(.4, 0.4, 0.4, 0.4))                                 # build plot frame
for(x in 1:length(sppx)){
  if(x < 9) {
    species_data <- subset(total, spp == sppx[x])
  } else{
    species_data <- total
  }
   tp_predict = as.data.frame(matrix(ncol=1000,nrow=126))
  
  for (i in 1:S){
    new_df <- ddply(species_data,.(year),function(x) x[sample(nrow(x),1),])   # sample value from each available year
    tp_est <- loess(tp ~ year, new_df,span = 1)                               # fit loess model through the series
    tp_predict[i] <- as.data.frame(predict(tp_est,data.frame(year = seq(1890, 2015,1)))) # predict for all years
  }
  tp_predict$year <- seq(1890, 2015, by = 1)
  test_data_long <- melt(tp_predict, id="year")
  
  #gather quantiles from data
  sum_data<- do.call(data.frame,aggregate(value ~ year, data = test_data_long, function(x) c(quantile(x,.975),quantile(x,.025),median(x) )))
  
  #build plots
  plot(sum_data$year,sum_data$value.V3, type = "l",col="blue",main = sppx[x], ylab = '',xlab = '',ylim=c(3.4,4.4))
  lines(sum_data$year,sum_data$value.97.5.,col="light blue")
  lines(sum_data$year,sum_data$value.2.5.,col="light blue")
  
  b<-1979
  
  #overlay Harrison et al. 1983 calculated trophic levels 
  if(x < 9) {
    z<-subset(preyMTL_data,spp = species_data$spp[x])
    y<-z$ad_mean_tl[x]
    points(b,y,pch = 20)
    sd<-z$SE_mean_TL[x]
    arrows(b,y-sd,b,y+sd, code=3, length=0.02, angle = 90)
    abline(h=subset(sum_data, year == 1891, select = value.V3 ),lty = "dotted" )
  }else{
    b<- 1979
    y<-mean(preyMTL_data$ad_mean_tl)
    points(b,y, pch = 20)
    sd<-mean(z$SE_mean_TL)
    arrows(b,y-sd,b,y+sd, code=3, length=0.02, angle = 90)
    abline(h=subset(sum_data, year == 1891, select = value.V3 ),lty = "dotted" )
  }
  
  labels_axes <- c("")
  y_ticks = c(3.4,3.5,3.6,3.7,3.8,3.9,4.0,4.1,4.2,4.3,4.4)
  x_ticks = c(1900,1910,1920,1930,1940,1950,1960,1970,1980,1990,2000,2010)
  axis(side = 1, at = x_ticks, labels = FALSE, outer = FALSE)
  axis(side = 2, at = y_ticks, labels = TRUE, outer = FALSE)
  
  title(tp_est $pars $span, outer = TRUE, cex = 1.5, line = -2)
}  
```



```{r, echo=FALSE,include=FALSE}
library(data.table)
library(MixSIAR)
library(dplyr)
library(plyr)
library(ggplot2)
library(R2jags)
```


__This is the Bayesian MCMC hierarchical mixing model that is used to estimate the proportion of prey contributing to diet at expected trophic positions__

We used hierarchal Bayesian mixing models (R package MixSIAR) to visualize shifts in diet proportions of prey sources across time. TP over time (Fig. 1) was the mixture biotracer response as a function of prey item assimilation. TL of 6 prey items were the source biotracer input. Year was incorporated as a continuous random effect. Uncertainty in source data TLs was built-in with estimates of mean and standard error from the literature and FishBase. We used a process error structure to account for variation in seabird trophic levels14. A process error structure permits consumers to sample in different locations from each prey source distribution, and subsequent variation in consumer tracer values is accounted for in this sampling process. Because trophic magnification from prey to predator is one, discrimination factors were fixed at one. 
Informative Dirichlet priors with the same weight as an uninformative prior were generated using the mean prey contribution estimates across the eight seabird species2. We generated the priors with the sum of the Dirichlet hyper parameters kept equivalent in weight to an uninformative prior (i.e. 4 for 4 source groups, Fig. S5) while maintaining the informative distribution. The mixing model was run for 3 chains over 100,000 iterations, removing 50,000 for burn-in and thinning by a factor of 50. 

*NOTE: this mardown is an abbreviated short MCMC run*
```{r,error=FALSE,tidy=TRUE,message = FALSE,warning=FALSE,results = "hide"}
sppx<-c("SOTE","WTSH","BRBO","BRNO","LAAL","BUPE","WTTR","WHTE")
#sppx<- "SOTE"
data_box = NULL

for(x in 1:length(sppx)){
mix<-read.csv('mixture_data_may22.csv')
str(mix)
mix<-subset(mix, spp == sppx[x])
write.csv(mix,file = "mixture_data_spp.csv")

#mix data = i.e. consumer
mix<- load_mix_data(filename = "mixture_data_spp.csv",iso_names = "TL",factors = "spp",
                          fac_random = TRUE,fac_nested = NULL,cont_effects = "year")
#source data #new omma and caran TL
source <- load_source_data( filename = "source_data_4grp_may22.csv",
                            source_factors = NULL,conc_dep = FALSE,data_type = "means",mix)
#discrimination data
discr <- load_discr_data(filename = "discrimination_data_4grp.csv",mix)
#one dimensional isospace plot
#plot_data(filename="isospace_plot",
 #     plot_save_pdf=FALSE,
  #    plot_save_png=FALSE,
   #   mix,source,discr)
#uninformative prior = alpha.prior = 1
#construct informative prior from stomach_proportional_plot_apr13.xlsx
TP_prior <- c(0.508,1.212,1.175,1.105)
#plot_prior(alpha.prior = TP_prior, source,
 #         plot_save_pdf=FALSE,
  #       plot_save_png=FALSE)
#write jags model
model_filename <- "MixSIAR_model.txt"
resid_err <- FALSE
process_err <- TRUE
write_JAGS_model(model_filename, resid_err,process_err, mix, source)
#run model
jags.1 <- run_model(run="test",mix,source,discr,model_filename,
                    alpha.prior = TP_prior,resid_err,process_err)
##########################
##########################
R2jags::attach.jags(jags.1)
n.sources <- source$n.sources
source_names <- source$source_names

      fac.lab <- mix$FAC[[1]]$labels
      label <- mix$cont_effects
      cont <- mix$CE[[1]] #either CE or CE_orig explore implications?
      ilr.cont <- get(paste("ilr.cont",1,sep=""))
      
      get_high <- function(x){return(quantile(x,.95))}
      get_low <- function(x){return(quantile(x,.05))}
      
      n.plot = 124 #200 was original consider changing to number of years? which I did
      chain.len = dim(p.global)[1]
      Cont1.plot <- seq(from=round(min(cont),1), to=round(max(cont),1), length.out=n.plot)
      ilr.plot <- array(NA,dim=c(n.plot, n.sources-1, chain.len))
      ilr.median <- array(NA,dim=c(n.plot, n.sources-1))
      ilr.low <- array(NA,dim=c(n.plot, n.sources-1))
      ilr.high <- array(NA,dim=c(n.plot, n.sources-1))
      for(src in 1:n.sources-1){
        for(i in 1:n.plot){
          ilr.plot[i,src,] <- ilr.global[,src] + ilr.cont[,src]*Cont1.plot[i] #+ ilr.fac1[,f1,src]
          ilr.low[i,src] <- get_low(ilr.plot[i,src,])
          ilr.median[i,src] <- median(ilr.plot[i,src,])  #changed from median to mean 
          ilr.high[i,src] <- get_high(ilr.plot[i,src,])
        }
      }
      
      # Transform regression lines from ILR-space to p-space
      e <- matrix(rep(0,n.sources*(n.sources-1)),nrow=n.sources,ncol=(n.sources-1))
      for(i in 1:(n.sources-1)){
        e[,i] <- exp(c(rep(sqrt(1/(i*(i+1))),i),-sqrt(i/(i+1)),rep(0,n.sources-i-1)))
        e[,i] <- e[,i]/sum(e[,i])
      }
      cross.med <- array(data=NA,dim=c(n.plot, n.sources, n.sources-1))  # dummy variable for inverse ILR calculation
      tmp.p.med <- array(data=NA,dim=c(n.plot, n.sources))              # dummy variable for inverse ILR calculation
      p.median <- array(data=NA,dim=c(n.plot, n.sources))
      cross.low <- array(data=NA,dim=c(n.plot, n.sources, n.sources-1))  # dummy variable for inverse ILR calculation
      tmp.p.low <- array(data=NA,dim=c(n.plot, n.sources))              # dummy variable for inverse ILR calculation
      p.low <- array(data=NA,dim=c(n.plot, n.sources))
      cross.high <- array(data=NA,dim=c(n.plot, n.sources, n.sources-1))  # dummy variable for inverse ILR calculation
      tmp.p.high <- array(data=NA,dim=c(n.plot, n.sources))              # dummy variable for inverse ILR calculation
      p.high <- array(data=NA,dim=c(n.plot, n.sources))
      for(i in 1:n.plot){
        for(j in 1:(n.sources-1)){
          cross.med[i,,j] <- (e[,j]^ilr.median[i,j])/sum(e[,j]^ilr.median[i,j]);
          cross.low[i,,j] <- (e[,j]^ilr.low[i,j])/sum(e[,j]^ilr.low[i,j]);
          cross.high[i,,j] <- (e[,j]^ilr.high[i,j])/sum(e[,j]^ilr.high[i,j]);
        }
        for(src in 1:n.sources){
          tmp.p.med[i,src] <- prod(cross.med[i,src,]);
          tmp.p.low[i,src] <- prod(cross.low[i,src,]);
          tmp.p.high[i,src] <- prod(cross.high[i,src,]);
        }
        for(src in 1:n.sources){
          p.median[i,src] <- tmp.p.med[i,src]/sum(tmp.p.med[i,]);
          p.low[i,src] <- tmp.p.low[i,src]/sum(tmp.p.low[i,]);
          p.high[i,src] <- tmp.p.high[i,src]/sum(tmp.p.high[i,]);
        }
      }
      colnames(p.median) <- source_names
    
      Cont1.plot <-  Cont1.plot*35.93976 + mix$CE_center # transform Cont1.plot (x-axis) back to the original scale
      df <- data.frame(reshape2::melt(p.median)[,2:3], rep(Cont1.plot,n.sources), reshape2::melt(p.low)[,3], reshape2::melt(p.high)[,3])
      colnames(df) <- c("source","median","x","low","high")
      
      # Plot of Diet vs. Cont effect
      #Fill##

      df$spp <- ifelse(df$high < 100, sppx[x])
      
      data_box = rbind(data_box,df)
}
###################
###END MCMC LOOP###
###################
```


```{r, fig.retina=2}

data_box$spp <- as.factor(data_box$spp)
data_box$spp <- factor(data_box$spp, levels=c("LAAL", "BUPE", "WTSH", "WTTR", "BRBO","BRNO","WHTE","SOTE","TP"))

#data_box <- subset(data_box, spp == c("LAAL", "BUPE", "WTSH", "WTTR", "BRBO","BRNO","WHTE","SOTE"))

ggplot(data_box, aes(x=x))+geom_line(aes(y=median,color = source),size = 1)+scale_color_brewer(type = "seq",palette = 'Spectral' )+facet_wrap(~spp,ncol =2)+theme_classic()+ 
  theme(strip.background = element_blank(),
        panel.border = element_rect(colour = "black", fill=NA, size=.5),
        legend.title=element_blank(),
        strip.text=element_text(hjust=0))+
  xlab("year")+
  ylab("proportion of diet")

```

```{r, echo=FALSE,include=FALSE}
library(reshape)
library(ggplot2)
library(pdp)
library(dplyr)
library(caret)
library(randomForest)
library(ALEPlot)
library(pdp)
```

Random Forest model development


_Set working directory and read in dataset_

Read in reconstuctured Sea Around Us project data



```{r}
famandspp<-read.csv("SAULandings_familyandspp.csv", header = T)
```
a plot to take a look at it 
```{r,fig.retina=2}
a<-ggplot(famandspp,aes(x=year,y=sqrt(sumcatch)))+
  geom_line(aes(color=Taxon.Name))+theme_bw()
a
```

recast and from in to df with columns for catch taxa
```{r}
df <- data.frame(cast(famandspp, year ~ Taxon.Name ))
```

_Bring in old dataset_
```{r}
bigger_data<-read.csv("final_dataset_may10.csv", header = T)
###EDIT BUPE FORAGE DIST TO 350###
BUPE_new_forage_dist <- 350
bigger_data$forage_dist[bigger_data$spp == "BUPE"] <- BUPE_new_forage_dist
###NOTE: for lag variable incorporation, must be run post 1951 due to NPGO availability up to 1950
#subset out post 1950 data
```

_Subset out post-1950 and merge in SAU data_
```{r}
full_data <- subset(bigger_data,year >= 1951)
#merge in SAU fisheries
test<-merge(full_data,df,by="year")
full_data <- test
str(full_data)
###################################################
#set seed to replicate bootstrapping nature of RF##
###################################################
set.seed(123)
```

 __Data post-simulation, boxplots by year of trophic position estimates drawn from feather specimens.__
 _Red dotted line represents 1951, the year from which all climate, climate lag, and fisheries data is complete and the time period cutoff for the data input in to the random forest model._
 
```{r,fig.retina=2}
plot <- bigger_data
plot$spp <- factor(plot$spp, levels=c("LAAL", "BUPE", "WTSH", "WTTR", "BRBO","BRNO","WHTE","SOTE","TP"))
ggplot(plot,aes(x=year,y=tp))+
  geom_boxplot(aes(x=year,y=tp,group=as.factor(year)),outlier.shape = NA)+
  facet_wrap(~spp,ncol = 4)+
  geom_vline(xintercept=1951,linetype="dotted",color = "red")+
  theme_classic()+
  theme(axis.title.y=element_blank(),
                       strip.background = element_blank(),
                       panel.border = element_rect(colour = "black", fill=NA, size=.5),
                       legend.position = c(0.15, 0.8),
                       legend.key.size = unit(.75, "cm"),
                       legend.title=element_blank(),
                       strip.text=element_text(hjust=0))+ylab("trophic position")+
  stat_summary(fun.y=mean, geom="line", aes(group = 1)) 
```

This the syntax input of the randomForest model input. ntree is the number of trees used to build the model. A data partition to speed up/create a testset. Then a formula expression of the model to be built

*NOTE: This is an abbreviate randomForest model, ntree is fixed at 100 to reduce computation time.
```{r}
#################################
#################################
#####Full model Development######
#################################

ntree = 100
#create data partition for training set 
InTrain<-createDataPartition(full_data$spp,p=0.8,list=FALSE)
#partion out training set
training1<-full_data[InTrain,]
#partition out validation/test set
testing1<-full_data[-InTrain,]
Seabird_Random_Forest <- randomForest(tp ~ #current climate
                            MEIave_by_year +PDOave_by_year +NPGOyear_mean +avgTemp +
                            #lagged climate
                            PDOlag1 +NPGOlag1 +avgTemplag1 +MEIlag1 +
                            #prey pressure/abundance
                            Carangidae +Exocoetidae +Mullidae +Ommastrephidae +
                            #morphology
                            forage_dist + wing_load + spp + 
                            #timeline
                            year,
                          data=training1,
                          importance = TRUE,
                          ntree = ntree)

```

__Variable importance and OOB error improvement__
We utilized a variable importance metric that measures reduction of mean squared error of a model when a predictor is randomly permuted (i.e. ‘noised up’), which allows for a rank order of variable influence on the model.

```{r, fig.width=10, fig.height=5,echo=FALSE,fig.retina=2}
par(mfrow = c(1,2))
#variable importance plot
varImpPlot(Seabird_Random_Forest, type = 1)
#ntree error plot
plot(Seabird_Random_Forest)
```

__Partial dependence plots__
Partial dependence plots visualize the average partial relationship between the predicted response and a predictor conditioned on all other predictors. 

```{r, fig.width=10, fig.height=10,echo=FALSE,fig.retina=2}
##################################
##Conventional partial plot loop##
##################################
sonarimp <- importance(Seabird_Random_Forest)
impvar<- rownames(sonarimp)[order(sonarimp[,1],decreasing = TRUE)]
op <- par(no.readonly = TRUE)
par(mfrow = c(4, 4))
par(mar = c(2.5, 3.5, 1, 0.5))
par(mgp = c(1.5, 0.5, 0))
par(oma = c(0, 0, 3, 0))
for(i in 1:length(impvar)) {
imptvar <- impvar[i]
pd <- partial(Seabird_Random_Forest, pred.var = imptvar)
plot(pd[,1],pd[,2],type = 'l', xlab = colnames(pd)[1],ylab = 'tp')}
mtext("Partial dependency plots for Sea Around Us Project data random forest", outer = TRUE, side = 3, cex = 1.2, line =1)
```

__Partial dependence surface plots__

Selection of interactions between predictors and trophic position response. Yellow cells indicate relatively higher trophic position, relatively lower is blue. Polygons indicate the convex hull of the training values.

```{r, fig.width=10, fig.height=10,echo=FALSE,fig.retina=2}
load("partialData_may30.RData")
b1<-plotPartial(a1,chull=TRUE,train=training1,at= )
b2<-plotPartial(a2,chull=TRUE,train=training1,at= ) #chull is logical indicating whether to show convex hull of training values
b3<-plotPartial(a3,chull=TRUE,train=training1,at= )
b4<-plotPartial(a4,chull=TRUE,train=training1,at= )
b5<-plotPartial(a5,chull=TRUE,train=training1,at= )
b6<-plotPartial(a6,chull=TRUE,train=training1,at= )
b7<-plotPartial(a7,chull=TRUE,train=training1,at= )
b8<-plotPartial(a8,chull=TRUE,train=training1,at= )
b9<-plotPartial(a9,chull=TRUE,train=training1,at= )
b10<-plotPartial(a10,chull=TRUE,train=training1,at=)
b11<-plotPartial(a11,chull=TRUE,train=training1,at=)
b12<-plotPartial(a12,chull=TRUE,train=training1,at= )
b13<-plotPartial(a13,chull=TRUE,train=training1,at= )
#b14<-plotPartial(a14,chull=TRUE,train=training1,at= )
grid.arrange(b1,b2,b3,b4,b5,b6,b7,b8,b9,b10,b11,b12,b13,ncol=4,nrow = 4)
```

__Individual conditional expectation (ICE) plots__

ICE plots function as refined partial dependence plots showing the functional relationship between the predicted response and the feature for a subset of individual observations. ICE plots effectively highlight the variation in fitted values. Predictors are pinched at minimum observed value such that the right vertical axis displays change in the response over the baseline as fraction of the response’s observed range. While the left y-axis shows a conventional, centered conditional response akin to a traditional partial dependence plot (yellow highlighted black line). Plots showing wedges acorss their range are more interactive (forage dist, wingload,MEIave, avgTemplag1, etc) than those showing primarily parallel responses which tend to be addititive (year, mullidae, MEI lag1). Plots are rank ordered by variable importance as a measure of percent mean squared error reduction under permutation. 


BUILDING ICE PLOTS FOR FIGURE

```{r}
library(ICEbox)
Z <- subset(training1, select = c("tp", "MEIave_by_year","PDOave_by_year","NPGOyear_mean" ,"avgTemp" ,
                                  "PDOlag1", "NPGOlag1","avgTemplag1" ,"MEIlag1" ,
                                  "Carangidae" ,"Exocoetidae" ,"Mullidae" ,"Ommastrephidae" ,
                                  "forage_dist" , "wing_load" , "spp" , 
                                  "year"))
final_fit <- randomForest(Z[,2:17],Z[,1],ntree = ntree, importance = TRUE)
sonarimp <- importance(final_fit)
impvar<- rownames(sonarimp)[order(sonarimp[,1],decreasing = TRUE)]
impvar <- impvar[2:16]
```

```{r, fig.width=10, fig.height=10,echo=FALSE, message = FALSE,fig.retina=2}
plot.new()
op <- par(no.readonly = TRUE)
par(mfrow = c(4, 4))
par(mar = c(2.5, 3.5, 1, 1.5))
par(mgp = c(1.5, 0.5, 0))
par(oma = c(0, 0, 3, 0))

for(i in 1:length(impvar)) {
  imptvar <- impvar[i]
  pd_ice <- ice(object = final_fit, X = Z[,2:17], y = Z[,1], predictor = imptvar, frac_to_build = .1,verbose = FALSE)
  plot(pd_ice, x_quantile = TRUE, plot_pdp = TRUE, frac_to_plot = 1, centered = TRUE,pts_preds_size = .5)}

mtext("Individual conditional expectation plots for Sea Around Us Project data random forest", outer = TRUE, side = 3, cex = 1.2, line =1)
```


```{r, include=FALSE}
library(reshape)
library(ggplot2)
library(grid)
library(gridExtra)
library(randomForest)
#partial 2d - dependence data : df1 - df12
load("convenpdepData_June6.RData")
#partial 3d - dependence data : a1 - a14
load("partialData_may30.RData")
#varimp scale data
load("scale_June6.RData")
#rf model
final_fit <- readRDS("final_fit_full_may26_SAU.rds")

```

__Single Column Imp Plot__

generate and index variable importance single column gradient plot
```{r,error=FALSE}
importance <- as.data.frame(melt(importance(final_fit,type=1)))
###importance gradient###
importance <- importance[-c(15,16),] #remove year and spp
#scale 0 to 1 
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
importance$value <- range01(importance$value)
importance$value <- round(importance$value,digits=2)
importance$X1 <- factor(importance$X1, levels = importance$X1[order(importance$value)])
scale<-ggplot(importance,aes(x = X2, y = X1, fill = value))+
  geom_tile(show.legend = FALSE) + 
  geom_label(aes(label=value),size = 2.5,fill = "white",label.r = unit(0,"lines"),nudge_x = 0,nudge_y = -.05,vjust = "top",hjust="center")+
  geom_label(aes(label=X1),size = 2.5, fill = "white",label.r = unit(0,"lines"),nudge_x = 0,nudge_y = 0.1,vjust = "bottom",hjust="center")+
  theme_classic() +
  scale_fill_gradient(low = "white",high = "black") +
  scale_x_discrete(position = "top") +
  theme(axis.title.x.top =element_blank(),
        axis.title.y = element_blank(),
        axis.text.y=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.y=element_blank(),
        axis.ticks.x=element_blank())+
  theme_void()
```

rename partial dependence dataframe columns
```{r}
colnames(df1) <- c("forage_dist","trophic_position")
colnames(df2) <- c("carangidae","trophic_position")
colnames(df3) <- c("mullidae","trophic_position")
colnames(df4) <- c("MEI","trophic_position")
colnames(df5) <- c("ommastrephidae","trophic_position")
colnames(df6) <- c("wing_load","trophic_position")
colnames(df7) <- c("PDOlag","trophic_position")
colnames(df8) <- c("NPGO","trophic_position")
colnames(df9) <- c("MEIlag","trophic_position")
colnames(df10) <- c("SST","trophic_position")
colnames(df11) <- c("PDO","trophic_position")
colnames(df12) <- c("SSTlag","trophic_position")

#melt and reshape
a<-Reduce(function(x, y) merge(x, y, all=TRUE), list(df1, df2, df3,df4,df5,df6,df7,df8,df9,df10,df11,df12))
b<-as.data.frame(scale(a[,2:13]))
a<-cbind(a$trophic_position,b)
a<-melt(a,id.vars = c(1))
colnames(a) <- c("trophic_position","predictor","value")
```

__Develop faceted partial dependence plot__
```{r}
a$predictor <- factor(a$predictor, levels=c("carangidae", "mullidae", "ommastrephidae", "wing_load", "forage_dist","PDOlag","NPGO","MEIlag","SST","PDO","SSTlag","MEI"))
pdep2d<-ggplot(a,aes(y=trophic_position,x=value))+geom_line()+facet_wrap(~predictor,nrow=3)+xlab(NULL)+
  theme(axis.title.y=element_blank(),axis.ticks.y=element_blank(),strip.background = element_blank(),panel.border = element_rect(colour = "black", fill=NA, size=.5),legend.title=element_blank(),
                              strip.text=element_text(hjust=0))
```


Build heatmap function that allows partial depenedence data input, specify axes, and ramp gradient color hex.
```{r}
heatmap <- function(data,x,y,high.col){
  x<-substitute(x)
  y<-substitute(y)
  yhat <-data[,3]
  g<-ggplot(data,aes_string(x=x,y=y,fill=yhat))+geom_tile(show.legend = FALSE)+scale_fill_gradient(low="white", high= high.col)+
    scale_y_continuous(expand = c(0,0)) +scale_x_continuous(expand = c(0,0)) +theme(axis.ticks.y=element_blank(),text=element_text(size=12, family="Calibri"),axis.ticks.x=element_blank())+theme_classic()
    return(g)}
  
#Fish only - #66c2a5
#eco morph - #fdae61
#climate - #3288bd
#mix - #d53e4f
```

```{r,include=FALSE}
wing_x_forage<-heatmap(data=a1,x=forage_dist,y=wing_load,"#fdae61")
caran_x_mulli<-heatmap(data=a2,x=Carangidae/10000,y=Mullidae/100,"#66c2a5")
PDOlag_x_NPGO<-heatmap(data=a3,x=PDOlag1,y=NPGOyear_mean,"#3288bd")
SST_x_PDO<-heatmap(data=a4,x=avgTemp,y=PDOave_by_year,"#3288bd")
omma_x_caran<-heatmap(data=a5,x=Ommastrephidae/10000,y=Carangidae/10000,"#66c2a5")
omma_x_mull<-heatmap(data=a6,x=Ommastrephidae/10000,y=Mullidae/100,"#66c2a5")
NPGOlag_x_exoco<-heatmap(data=a7,x=NPGOlag1,y=Exocoetidae,"#d53e4f")
MEI_x_NPGO<-heatmap(data=a8,x=MEIave_by_year,y=NPGOyear_mean,"#3288bd")
caran_x_PDOlag<-heatmap(data=a9,x=Carangidae/10000,y=PDOlag1,"#d53e4f")
omma_x_NPGO<-heatmap(data=a10,x=Ommastrephidae/10000,y=NPGOyear_mean,"#2ca25f")
forage_x_omma<-heatmap(data=a12,x=forage_dist,y=Ommastrephidae/10000,"#d53e4f")

```

```{r,include=FALSE}
##########################
#Build grobs##
##########################
#scaled importance
g1 <- ggplotGrob(scale)
#pdep 2d plots
g2 <- ggplotGrob(pdep2d)
#interactive plots
wing_x_forage <- ggplotGrob(wing_x_forage)
caran_x_mulli <- ggplotGrob(caran_x_mulli)
PDOlag_x_NPGO <- ggplotGrob(PDOlag_x_NPGO)
SST_x_PDO <- ggplotGrob(SST_x_PDO)
omma_x_caran <- ggplotGrob(omma_x_caran)
MEI_x_NPGO <- ggplotGrob(MEI_x_NPGO)
caran_x_PDOlag <- ggplotGrob(caran_x_PDOlag)
forage_x_omma <- ggplotGrob(forage_x_omma)

lay<-rbind(c(1,2,2,2,2,3,3,4,4),
           c(1,2,2,2,2,5,5,6,6),
           c(1,2,2,2,2,7,7,8,8))

```

```{r,fig.width=13, fig.height=6,fig.retina=2}
grid.arrange(
  #first column
  g1,
  #second facet block
  g2,
  
  #row1
  caran_x_mulli,
  omma_x_caran,
  #row2
  wing_x_forage,
  forage_x_omma,
  
  #row3
  PDOlag_x_NPGO,
  SST_x_PDO,

            layout_matrix = lay)
```

